---
- name: firewall configuration 
  become: yes
  shell: |
    systemctl enable firewalld ; 
    systemctl start firewalld ;
    firewall-cmd --permanent --add-port=6443/tcp; 
    firewall-cmd --permanent --add-port=2379-2380/tcp; 
    firewall-cmd --permanent --add-port=10250-10255/tcp;
    firewall-cmd --reload

- name: 'Make sure kubelet service is running on worker nodes'
  systemd:
    name: kubelet
    enabled: true
    state: started
  become: true

- name: initialize the cluster
  shell: sudo kubeadm init --apiserver-advertise-address=149.100.159.199 --pod-network-cidr=10.244.0.0/16
  args:
    chdir: $HOME

- name: create .kube directory
  become: yes
  become_user: harouna
  file:
    path: $HOME/.kube
    state: directory
    mode: 0755

- name: copies admin.conf to user's kube config
  copy:
    src: /etc/kubernetes/admin.conf
    dest: /home/harouna/.kube/config
    remote_src: yes
    owner: harouna

        
- name: Get the token for joining the worker nodes
  become: yes
  become_user: harouna
  shell: kubeadm token create  --print-join-command
  register: kubernetes_join_command

- debug:
    msg: "{{ kubernetes_join_command.stdout }}"

- name: Copy join command to local file.
  become: yes
  local_action: copy content="{{ kubernetes_join_command.stdout_lines[0] }}" dest="/tmp/kubernetes_join_command" mode=07


